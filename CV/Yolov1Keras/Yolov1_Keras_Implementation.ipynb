{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov1-Keras-Implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOenhqMDhd14aSWc4eU3rhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtossDragoon/CoMoLab/blob/master/CV/Yolov1Keras/Yolov1_Keras_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS5a4BamjxbH"
      },
      "source": [
        "# Yolov1 Model \n",
        "\n",
        "In this notebook I am going to implement YOLOV1 as described in the paper You Only Look Once. The goal is to replicate the model as described in the paper and in the process, understand the nuances of using Keras on a complex problem.\n",
        "\n",
        "- https://www.maskaravivek.com/post/yolov1/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYfx8Q9-jb-0",
        "outputId": "6f27afe9-ab6e-4f59-c2f0-cd0fd18be083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1MZWYKyjqXB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ehwq3xVjlJP"
      },
      "source": [
        "Data Preprocessing\n",
        "I would be using VOC 2007 dataset as its size is manageable so it would be easy to run it using Google Colab.\n",
        "\n",
        "First, I download and extract the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFXsTW7jk4v"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/\n",
        "!rm -r temp\n",
        "!mkdir temp\n",
        "%cd temp\n",
        "\n",
        "\n",
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
        "!wget http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
        "\n",
        "!tar xvf VOCtrainval_06-Nov-2007.tar # 현재 디렉터리에 tar file 의 압축을 푸는 코드\n",
        "!tar xvf VOCtest_06-Nov-2007.tar\n",
        "\n",
        "!rm VOCtrainval_06-Nov-2007.tar\n",
        "!rm VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKHsaw-3ksjB",
        "outputId": "31559e5c-2f74-45ef-9b89-d0801632de1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/temp\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VOCdevkit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f2sNIobkMqo"
      },
      "source": [
        "*위 데이터를 한 번 다운받았으면 다시는 다운 받을필요가 없겠지요? 매우 오랜 시간이 걸리는 작업이니 주의해 주세요.\n",
        "\n",
        "Next, we process the annotations and write the labels in a text file. A text file is easier to consume as compared to XML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YF4J9HHkMet"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/temp\n",
        "\n",
        "import argparse\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Build Annotations.')\n",
        "parser.add_argument('dir', default='..', help='Annotations.')\n",
        "\n",
        "sets = [('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
        "\n",
        "# 내가 관심있는 class 들과 그에 해당하는 번호\n",
        "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
        "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
        "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
        "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
        "\n",
        "\n",
        "def convert_annotation(year, image_id, f):\n",
        "    in_file = os.path.join('VOCdevkit/VOC%s/Annotations/%s.xml' % (year, image_id))\n",
        "    tree = ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for obj in root.iter('object'): # python 반복자 참고 : https://python.bakyeono.net/chapter-7-4.html \n",
        "                                    # xmltree xmlparser iter() 참고 : https://docs.python.org/2/library/xml.etree.elementtree.html#finding-interesting-elements\n",
        "        difficult = obj.find('difficult').text # difficult 가 뭔지는 잘 모르겠음.\n",
        "        cls = obj.find('name').text\n",
        "        classes = list(classes_num.keys())\n",
        "        if cls not in classes or int(difficult) == 1: # 내가 관심있는 class 가 아니면 버림.\n",
        "            continue\n",
        "        cls_id = classes.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text),\n",
        "             int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
        "        f.write(' ' + ','.join([str(a) for a in b]) + ',' + str(cls_id)) # join 함수 참고 : https://zetawiki.com/wiki/%ED%8C%8C%EC%9D%B4%EC%8D%AC_join()\n",
        "        # 함수가 파일에 쓰는 형식 : \n",
        "        # \" xmin,ymin,xmax,ymax,1 xmin,ymin,xmax,ymax,3 (...object의 개수만큼)\"\n",
        "\n",
        "\n",
        "for year, image_set in sets:\n",
        "  print(year, image_set)\n",
        "  with open(os.path.join('VOCdevkit/VOC%s/ImageSets/Main/%s.txt' % (year, image_set)), 'r') as f: # python context manager 참고 : https://sjquant.tistory.com/12\n",
        "      image_ids = f.read().strip().split() # 파일 입출력 참고 : https://wikidocs.net/26\n",
        "  with open(os.path.join(\"VOCdevkit\", '%s_%s.txt' % (year, image_set)), 'w') as f:\n",
        "      for image_id in image_ids:\n",
        "          f.write('%s/VOC%s/JPEGImages/%s.jpg' % (\"VOCdevkit\", year, image_id))\n",
        "          convert_annotation(year, image_id, f)\n",
        "          f.write('\\n')\n",
        "          # for 문 반복 한번 당 파일에 작성되는 형식 :\n",
        "          # \"VOCdevkit/VOC2007/JPEGImages/이미지명.jpg xmin,ymin,xmax,ymax,1 xmin,ymin,xmax,ymax,3 (...object의 개수만큼)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImgNvaHIkoTp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6pWiFBTko4j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}