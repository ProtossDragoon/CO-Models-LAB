{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bisenetv2-tensorflow-and-optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ulzQ8TLqwpSarcUB-UNiiUDl0Tz5veWl",
      "authorship_tag": "ABX9TyPssz/KMkESL4rQ46NhNGsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtossDragoon/CoMoLab/blob/master/CV/Segmentation/bisenetv2_tensorflow_and_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRZ9tGbkfGdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a61c14-35fb-4d76-8cf1-02217990a3d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtlT_1YvXLHK",
        "outputId": "05334368-939e-4b63-cf6b-a72065cb4d8e"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXnYP97JXFXe",
        "outputId": "c7d69e44-fecd-41d6-e6fc-2a1f84a52c4c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Dec  3 00:52:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "nkG0icMnHRI5",
        "outputId": "bce110eb-e02a-4bd4-8d97-99edc5e8e547"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/WhitePaper\n",
        "!git clone https://github.com/ProtossDragoon/bisenetv2-tensorflow.git\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-8828bcec6f92>\", line 1, in <module>\n",
            "    get_ipython().magic('cd /content/gdrive/\"My Drive\"/WhitePaper')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
            "    return self.run_line_magic(magic_name, magic_arg_s)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
            "    result = fn(*args,**kwargs)\n",
            "  File \"<decorator-gen-91>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/osm.py\", line 288, in cd\n",
            "    oldcwd = py3compat.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tP42W9nfvdh",
        "outputId": "681abe27-67da-4697-eba1-6e28fcacce3c"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npY0PIUwf0z1",
        "outputId": "9be1bf22-3f71-4c00-d280-f626d231c39d"
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/WhitePaper/bisenetv2-tensorflow\n",
        "%ls -al\n",
        "\n",
        "# 프로그램 실행 시 반드시 bisenetv2-tensorflow 위치로 접근할 것.\n",
        "# --weights_path 은 정확한 이름이 아니라 ckpt 까지만 지정해 주면 됨. xxxx of xxxx 파일도 반드시 필요함.\n",
        "# --src_image_path 을 원래 이미지 하나만 지정해야 동작했는데, 경로로 지정하면 거기에 있는 모든 이미지를 전부 segmentation 하도록 코드를 편집함.\n",
        "# test_bisenetv2_cityscapes.py 만 수정한 상태임.\n",
        "!python3 ./tools/cityscapes/test_bisenetv2_cityscapes.py --weights_path ./model/cityscapes/bisenetv2/cityscapes.ckpt --src_image_path ./data/test_image/cityscapes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow\n",
            "total 62\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[0m\u001b[01;34mbisenet_model\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mconfig\u001b[0m/\n",
            "-rw------- 1 root root   26 Dec  1 04:11 _config.yml\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mdata\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 14:30 \u001b[01;34mdata_output\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mdata_provider\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 05:56 \u001b[01;34m.git\u001b[0m/\n",
            "-rw------- 1 root root 1530 Dec  1 04:11 .gitignore\n",
            "drwx------ 2 root root 4096 Dec  1 14:30 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
            "-rw------- 1 root root 1072 Dec  1 04:11 LICENSE\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mlocal_utils\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 04:13 \u001b[01;34mmodel\u001b[0m/\n",
            "-rw------- 1 root root 9492 Dec  1 04:11 README.md\n",
            "-rw------- 1 root root  127 Dec  1 04:11 requirements.txt\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mscripts\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mtools\u001b[0m/\n",
            "drwx------ 2 root root 4096 Dec  1 04:11 \u001b[01;34mtrainner\u001b[0m/\n",
            "-------version-------\n",
            "tensorflow version 1.15.2\n",
            "-------version-------\n",
            "-------path parsing-------\n",
            "/content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow\n",
            "model/cityscapes/bisenetv2/cityscapes.ckpt\n",
            "/content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/model/cityscapes/bisenetv2/cityscapes.ckpt\n",
            "data/test_image/cityscapes\n",
            "/content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data/test_image/cityscapes\n",
            "this is a path\n",
            "-------path parsing-------\n",
            "WARNING:tensorflow:From ./tools/cityscapes/test_bisenetv2_cityscapes.py:129: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/bisenet_v2.py:1138: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/cnn_basenet.py:71: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/cnn_basenet.py:401: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/cnn_basenet.py:222: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/cnn_basenet.py:246: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/bisenet_model/bisenet_v2.py:583: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From ./tools/cityscapes/test_bisenetv2_cityscapes.py:142: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From ./tools/cityscapes/test_bisenetv2_cityscapes.py:146: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-03 00:53:12.815840: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-12-03 00:53:12.816083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2cbe840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-03 00:53:12.816118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-03 00:53:12.819719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-03 00:53:13.017083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:13.017801: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2cbed80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-03 00:53:13.017833: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-12-03 00:53:13.018581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:13.019116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-12-03 00:53:13.019412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-03 00:53:13.226596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-03 00:53:13.358821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-03 00:53:13.375732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-03 00:53:13.646553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-03 00:53:13.666010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-03 00:53:14.171683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-03 00:53:14.171873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:14.172560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:14.173095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-12-03 00:53:14.175271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-03 00:53:14.176638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-03 00:53:14.176667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-12-03 00:53:14.176679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-12-03 00:53:14.177767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:14.178368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-03 00:53:14.178931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13571 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From ./tools/cityscapes/test_bisenetv2_cityscapes.py:155: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "['test_01.png', 'test_02.png', 'test_03.png', '.ipynb_checkpoints', '11.00.17.png', '11.13.16.png', '11.13.10.png', '11.13.05.png', '11.12.59.png', '11.00.30.png', '11.12.52.png', '11.12.46.png', '11.12.41.png', '11.12.36.png', '11.12.32.png', '11.12.28.png', '11.12.22.png', '11.12.15.png', '11.12.10.png', '11.00.44.png', '11.00.51.png', '11.01.08.png', '11.11.46.png', '11.11.56.png', '11.12.05.png', '10.59.46.png']\n",
            "25 image(s) detected\n",
            "image test_01.png reading\n",
            "image test_01.png : shape (1024, 2048, 3)\n",
            "2020-12-03 00:53:24.095174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-03 00:53:29.203083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/test_01.png_output.jpg\n",
            "\n",
            "image test_02.png reading\n",
            "image test_02.png : shape (1024, 2048, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  5  6  7  8  9 10 11 13]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/test_02.png_output.jpg\n",
            "\n",
            "image test_03.png reading\n",
            "image test_03.png : shape (1024, 2048, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  4  5  7  8 10 11 13 14]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/test_03.png_output.jpg\n",
            "\n",
            "image 11.00.17.png reading\n",
            "image 11.00.17.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.00.17.png_output.jpg\n",
            "\n",
            "image 11.13.16.png reading\n",
            "image 11.13.16.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.13.16.png_output.jpg\n",
            "\n",
            "image 11.13.10.png reading\n",
            "image 11.13.10.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 15 16 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.13.10.png_output.jpg\n",
            "\n",
            "image 11.13.05.png reading\n",
            "image 11.13.05.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.13.05.png_output.jpg\n",
            "\n",
            "image 11.12.59.png reading\n",
            "image 11.12.59.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.59.png_output.jpg\n",
            "\n",
            "image 11.00.30.png reading\n",
            "image 11.00.30.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 16 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.00.30.png_output.jpg\n",
            "\n",
            "image 11.12.52.png reading\n",
            "image 11.12.52.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.52.png_output.jpg\n",
            "\n",
            "image 11.12.46.png reading\n",
            "image 11.12.46.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.46.png_output.jpg\n",
            "\n",
            "image 11.12.41.png reading\n",
            "image 11.12.41.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 15 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.41.png_output.jpg\n",
            "\n",
            "image 11.12.36.png reading\n",
            "image 11.12.36.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8 10 11 12 13 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.36.png_output.jpg\n",
            "\n",
            "image 11.12.32.png reading\n",
            "image 11.12.32.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.32.png_output.jpg\n",
            "\n",
            "image 11.12.28.png reading\n",
            "image 11.12.28.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 13 14 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.28.png_output.jpg\n",
            "\n",
            "image 11.12.22.png reading\n",
            "image 11.12.22.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 13 14 15 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.22.png_output.jpg\n",
            "\n",
            "image 11.12.15.png reading\n",
            "image 11.12.15.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.15.png_output.jpg\n",
            "\n",
            "image 11.12.10.png reading\n",
            "image 11.12.10.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.10.png_output.jpg\n",
            "\n",
            "image 11.00.44.png reading\n",
            "image 11.00.44.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.00.44.png_output.jpg\n",
            "\n",
            "image 11.00.51.png reading\n",
            "image 11.00.51.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.00.51.png_output.jpg\n",
            "\n",
            "image 11.01.08.png reading\n",
            "image 11.01.08.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 15 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.01.08.png_output.jpg\n",
            "\n",
            "image 11.11.46.png reading\n",
            "image 11.11.46.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.11.46.png_output.jpg\n",
            "\n",
            "image 11.11.56.png reading\n",
            "image 11.11.56.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.11.56.png_output.jpg\n",
            "\n",
            "image 11.12.05.png reading\n",
            "image 11.12.05.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/11.12.05.png_output.jpg\n",
            "\n",
            "image 10.59.46.png reading\n",
            "image 10.59.46.png : shape (1920, 2646, 3)\n",
            "Prediction mask unique label ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 17 18]\n",
            "save as : /content/gdrive/My Drive/WhitePaper/bisenetv2-tensorflow/data_output/test_image/cityscapes/10.59.46.png_output.jpg\n",
            "\n",
            "Mean cost time (inference ~ reshape ~ mapping): 0.52292s\n",
            "Mean fps (inference ~ reshape ~ mapping): 1.91235fps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUY27El3FzHt"
      },
      "source": [
        "# Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sp1hHkXV8SJ"
      },
      "source": [
        "## Convert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKTzuTs2V-pl"
      },
      "source": [
        "### keras h5 model to frozen .pb model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBSKMLU4Fxv1"
      },
      "source": [
        "le import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.framework import graph_io\n",
        "\n",
        "\n",
        "def keras_to_frozen_pb(model_in_path, \n",
        "                       model_out_path,\n",
        "                       tensor_out_name=None,\n",
        "                       tensorboard_dir=None):\n",
        "    \"\"\"\n",
        "    Converter that transforms keras model to frozen pb model\n",
        "    \n",
        "    Args:\n",
        "        model_in_path (str): Input model path (.h5) \n",
        "        model_out_path (str): Output model path (dir)\n",
        "        tensor_out_name (str, optional): Specified name of output tensor. \n",
        "                                         If None, it will get default tensor name from keras model.\n",
        "                                         Defaults to None.\n",
        "        tensorboard_dir (str, optional): Output tensorboard dir path for inspecting output model graph.\n",
        "                                         If None, it doesn't generate. \n",
        "                                         Defaults to None.\n",
        "    \"\"\"\n",
        "\n",
        "    graph = tf.Graph()\n",
        "    with graph.as_default():\n",
        "        sess = tf.Session()\n",
        "        K.set_session(sess)\n",
        "        K.set_learning_phase(0)\n",
        "\n",
        "        # load the model to graph and sess\n",
        "        model = tf.keras.models.load_model(model_in_path)\n",
        "\n",
        "        # get the tensor_out_name \n",
        "        if tensor_out_name is None:\n",
        "            print('tensor_out_name was not selected manually. it is going to selected automatically.')\n",
        "            if len(model.outputs) > 1:\n",
        "                raise NameError(\"the model has multiple output tensor. Need to specify output tensor name.\")\n",
        "            else:\n",
        "                print('model outptus : {}'.format(model.outputs))\n",
        "                print('selected model outputs : {}'.format(model.outputs[0].name.split(':')[0]))\n",
        "                tensor_out_name = model.outputs[0].name.split(\":\")[0]\n",
        "\n",
        "        # freeze the graph\n",
        "        # Turn all the variables into inline constants inside the graph and save it.\n",
        "\n",
        "        # select one !\n",
        "        # graph.as_graph_def() : method : Returns a serialized GraphDef representation of this graph.\n",
        "        # sess.graph_def : attribute : A serializable version of the underlying TensorFlow graph.\n",
        "        graphdef = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [tensor_out_name])\n",
        "        graphdef = tf.graph_util.remove_training_nodes(graphdef)\n",
        "\n",
        "        #params : \n",
        "        # graph_or_graph_def\n",
        "        # logdir : directory where to write the graph\n",
        "        # name : filename for the graph\n",
        "        graph_io.write_graph(graphdef, './', model_out_path, as_test = False)\n",
        "\n",
        "    if not tensorboard_dir is None:\n",
        "        tf.summary.FileWriter(logdir=tensorboard_dir, graph_def=graphdef)\n",
        "    \n",
        "    return tensor_out_name\n",
        "\n",
        "\n",
        "\n",
        "input_keras_model = \"modelpath\"\n",
        "output_pb_model = \"outputpath\"\n",
        "\n",
        "model_out_name = keras_to_frozen_pb(input_keras_model, output_pb_model)\n",
        "print(\"output node name : {}\".format(model_out_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hL3hEQMWEJz"
      },
      "source": [
        "### frozen pb to tensorRT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "cdMbopMDVkxy",
        "outputId": "15d80b5e-085f-42c6-88ae-e39acf59b40b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import uff\n",
        "import tensorrt as trt\n",
        "\n",
        "def frozen_pb_to_plan(model_path,\n",
        "                      output_path,\n",
        "                      tensor_in_name,\n",
        "                      tensor_out_name,\n",
        "                      input_size,\n",
        "                      data_type=trt.float32,\n",
        "                      max_batch_size=1,\n",
        "                      max_workspace=1<<30,\n",
        "                      tensorboard_dir=None):\n",
        "\n",
        "\n",
        "    # -----\n",
        "    # GFile : File I/O wrappers.\n",
        "      # read more : https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile\n",
        "    # read modelfile as binary format\n",
        "    graph_def = tf.GraphDef()\n",
        "    with tf.io.gfile.GFile(model_path, \"rb\") as f:\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    \n",
        "    # -----\n",
        "    # uff : a set of utilites to convert trained models\n",
        "    # Converts a TensorFlow frozen graph to a UFF model.\n",
        "    # The uff package contains a set of utilites to convert trained models from various frameworks to a common format.\n",
        "    # from_tensorflow_frozen_model returns serialized UFF MetaGraph (str)\n",
        "      # read more : https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/uff/uff.html\n",
        "    uff_model = uff.from_tensorflow_frozen_model(model_path, [tensor_out_name])\n",
        "\n",
        "    # create uff parser\n",
        "    parser = trt.UffParser()\n",
        "    parser.register_input(tensor_in_name, input_size)\n",
        "    parser.register_output(tensor_out_name)\n",
        "\n",
        "    # -----\n",
        "    # create trt logger and builder\n",
        "    trt_logger = tft.Logger(trt.Logger.INFO)\n",
        "    trt_builder = trt.Builder(trt_logger)\n",
        "\n",
        "    trt_builder.max_batch_size = max_batch_size\n",
        "    trt_builder.max_workspace_size = max_batch_size\n",
        "    trt_builder.fp16_mode = (data_type == trt.float16)\n",
        "\n",
        "    # parse the uff model to trt builder\n",
        "    network = tft_builder.create_network()\n",
        "    parser.parse_buffer(uff_model, network)\n",
        "    \n",
        "    # build optimized inference engine\n",
        "    engine = tft_builder.build_cuda_engine(network)\n",
        "\n",
        "    # save inference engine\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        f.write(engine.serialize())\n",
        "\n",
        "\n",
        "model_path = 'pb model path'\n",
        "output_path = 'output tensorrt plan path'\n",
        "tensor_in_name = 'input node name'\n",
        "tensor_out_name = 'output node name'\n",
        "input_size = [width, height, channel] # order – Input order on which the framework input was originally.\n",
        "\n",
        "frozen_pb_to_plan(model_path,\n",
        "                  output_path,\n",
        "                  tensor_in_name,\n",
        "                  tensor_out_name,\n",
        "                  input_size,\n",
        "                  data_type=trt.float32,\n",
        "                  max_batch_size=1,\n",
        "                  max_workspace=1<<30,\n",
        "                  tensorboard_dir=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-991c7a468196>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    with tf.io.gfile.GFile(model_path, ):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    }
  ]
}